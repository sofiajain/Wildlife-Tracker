import requests, pandas as pd

token = "eyJhbGciOiJIUzUxMiJ9.eyJ1c2VyX2lkIjo5OTIzNTUyLCJleHAiOjE3NjIwMDE4Nzd9.erWUHvGukvsONmW2TZSXoOM9J-wPA190BkXw0_Q_cKgFLDjBOaCZQgiOVBg_XSI7h5EIXoR6KAOCiu9Z6Y3ZbA"
headers = {"Authorization": f"Bearer {token}"}

url = "https://api.inaturalist.org/v1/observations"
params = {
    "taxon_name": "Delphinus delphis",  # common dolphin
    "per_page": 50,                     # up to 200 max
    "order_by": "created_at",
    "order": "desc"
}

r = requests.get(url, headers=headers, params=params)
r.raise_for_status()
data = r.json()

df = pd.DataFrame([
    {
        "species": obs["taxon"]["name"],
        "common_name": obs["taxon"].get("preferred_common_name"),
        "observed_on": obs["observed_on"],
        "lat": obs["geojson"]["coordinates"][1],
        "lon": obs["geojson"]["coordinates"][0],
        "place_guess": obs.get("place_guess"),
        "user": obs["user"]["login"]
    }
    for obs in data["results"]
])

df.head()



params = {
    "iconic_taxa": "Mammalia",  # or Animalia, Reptilia, etc.
    "marine": "true",
    "per_page": 100
}
r = requests.get("https://api.inaturalist.org/v1/observations", headers=headers, params=params)



def search_taxon(name):
    r = requests.get(f"https://api.inaturalist.org/v1/taxa", params={"q": name, "per_page": 5})
    r.raise_for_status()
    for t in r.json()["results"]:
        print(f"{t['id']:>7}  {t['name']:<25} ({t.get('preferred_common_name')})")

search_taxon("wild horse")
search_taxon("great white shark")



species_ids = {
    "domestic_horse": 209233,
    "wild_horse": 62629,
    "przewalski_horse": 62628,
    "kiang": 43338,
    "tarpan": 133980,
    "great_white_shark": 50873,
    "megalodon": 1493507
}



import requests, pandas as pd, time

token = "eyJhbGciOiJIUzUxMiJ9.eyJ1c2VyX2lkIjo5OTIzNTUyLCJleHAiOjE3NjIwMDE4Nzd9.erWUHvGukvsONmW2TZSXoOM9J-wPA190BkXw0_Q_cKgFLDjBOaCZQgiOVBg_XSI7h5EIXoR6KAOCiu9Z6Y3ZbA"
headers = {"Authorization": f"Bearer {token}"}

all_obs = []

for name, taxon_id in species_ids.items():
    url = "https://api.inaturalist.org/v1/observations"
    params = {
        "taxon_id": taxon_id,
        "per_page": 100,  # limit to 100 observations per species
        "order_by": "created_at",
        "order": "desc",
        "geo": "true"     # only observations with lat/lon
    }

    r = requests.get(url, headers=headers, params=params)
    if r.status_code == 200:
        data = r.json().get("results", [])
        for obs in data:
            if obs.get("geojson"):
                all_obs.append({
                    "species": obs["taxon"]["name"],
                    "common_name": obs["taxon"].get("preferred_common_name"),
                    "observed_on": obs["observed_on"],
                    "lat": obs["geojson"]["coordinates"][1],
                    "lon": obs["geojson"]["coordinates"][0],
                    "place_guess": obs.get("place_guess"),
                    "user": obs["user"]["login"]
                })
    else:
        print(f"❌ {name} failed ({r.status_code})")

    time.sleep(1)  # be nice to the API

df = pd.DataFrame(all_obs)
df.head()



print(df["species"].value_counts())
print(df.groupby("species")[["lat","lon"]].count())



df["observed_on"] = pd.to_datetime(df["observed_on"])
df = df.dropna(subset=["lat","lon"])  # remove any without coordinates

print("Earliest:", df["observed_on"].min())
print("Latest:",   df["observed_on"].max())
print(df.groupby("species")["user"].nunique().sort_values(ascending=False))



from folium import Map, plugins

m = Map(location=[20, 0], zoom_start=2)
heat_data = df[["lat", "lon"]].values.tolist()

plugins.HeatMap(heat_data, radius=10, blur=15, min_opacity=0.4).add_to(m)
m



import folium
from folium import plugins

# Filter for horse species only
horses = df[df["species"].str.contains("Equus")]

# Create map centered around average horse locations
m_horse = folium.Map(
    location=[horses["lat"].mean(), horses["lon"].mean()],
    zoom_start=2,
    tiles="CartoDB positron"
)

# Add a heatmap of horse sightings
plugins.HeatMap(
    horses[["lat", "lon"]].values.tolist(),
    radius=10, blur=15, min_opacity=0.4
).add_to(m_horse)

m_horse



m_species = folium.Map(location=[20, 0], zoom_start=2, tiles="CartoDB positron")

for sp, sub in df[df["species"].str.contains("Equus")].groupby("species"):
    folium.FeatureGroup(name=sp).add_child(
        plugins.HeatMap(sub[["lat","lon"]].values.tolist(),
                        radius=10, blur=15, min_opacity=0.4)
    ).add_to(m_species)

folium.LayerControl().add_to(m_species)
m_species



m_points = folium.Map(location=[20, 0], zoom_start=2, tiles="CartoDB positron")

for _, row in horses.iterrows():
    folium.CircleMarker(
        [row.lat, row.lon],
        radius=4,
        color="orange",
        fill=True,
        fill_opacity=0.6,
        popup=f"{row.common_name}<br>{row.place_guess}<br>{row.observed_on}"
    ).add_to(m_points)

m_points



colors = ["blue","red","green","purple","orange","pink","cadetblue"]
species_colors = dict(zip(df["species"].unique(), colors*3))

m_colored = folium.Map(location=[20, 0], zoom_start=2, tiles="CartoDB positron")
for _, r in df.iterrows():
    folium.CircleMarker(
        [r.lat, r.lon],
        radius=3,
        color=species_colors.get(r.species,"gray"),
        fill=True,
        fill_opacity=0.7
    ).add_to(m_colored)

m_colored



# ── Interactive Folium Map for iNaturalist Observations ───────────────────────
import pandas as pd
import numpy as np
import folium
from folium import plugins
from datetime import datetime
from ipywidgets import VBox, HBox, SelectionRangeSlider, SelectMultiple, Dropdown, Checkbox, IntSlider, Button, HTML, Layout, Output
from IPython.display import display, clear_output

# 0) Prep data
assert {'species','observed_on','lat','lon'}.issubset(df.columns), "df missing required columns"
work = df.copy().dropna(subset=['lat','lon']).copy()
work['observed_on'] = pd.to_datetime(work['observed_on'], errors='coerce', utc=True)
work = work.dropna(subset=['observed_on'])
if 'common_name' not in work.columns: work['common_name'] = None

# Helpers
def _bounds_latlon(d):
    return [d['lat'].mean() or 0, d['lon'].mean() or 0]

def _species_options():
    # stable sorted list
    return sorted(work['species'].dropna().unique().tolist())

def _date_range():
    mn = work['observed_on'].min().to_pydatetime()
    mx = work['observed_on'].max().to_pydatetime()
    # protect identical min/max
    if mn == mx:
        mx = mx + pd.Timedelta(days=1)
    return mn, mx

# 1) Widgets
sp_opts = _species_options()
date_min, date_max = _date_range()

w_species = SelectMultiple(
    options=sp_opts,
    value=tuple(sp_opts[: min(3, len(sp_opts))]),  # preselect a few
    description='Species',
    layout=Layout(width='330px', height='220px')
)

w_heatmap = Checkbox(value=True, description='Heatmap', indent=False)
w_points  = Checkbox(value=False, description='Show points', indent=False)
w_point_size = IntSlider(value=4, min=2, max=12, step=1, description='Point size', continuous_update=False)

w_tiles = Dropdown(
    options=[('CartoDB Positron','CartoDB positron'),
             ('OpenStreetMap','OpenStreetMap'),
             ('Stamen Terrain','Stamen Terrain'),
             ('CartoDB Dark','CartoDB dark_matter')],
    value='CartoDB positron', description='Basemap'
)

# Date slider as [left, right] with nice labels
w_dates = SelectionRangeSlider(
    options=[(d.strftime('%Y-%m-%d'), d) for d in pd.date_range(start=date_min.date(), end=date_max.date(), freq='D')],
    index=(0, (date_max.date() - date_min.date()).days),
    description='Dates',
    layout=Layout(width='600px'),
    continuous_update=False
)

w_export = Button(description='Export HTML', button_style='success', icon='download')
w_status = HTML(value='')
out_map = Output()

# 2) Renderer
def render_map(*args):
    with out_map:
        clear_output(wait=True)

        # filters
        sel_species = list(w_species.value) if w_species.value else sp_opts
        left, right = w_dates.value
        left = pd.to_datetime(left).tz_localize('UTC')
        right = pd.to_datetime(right).tz_localize('UTC') + pd.Timedelta(days=1) - pd.Timedelta(milliseconds=1)

        filt = work[
            work['species'].isin(sel_species) &
            (work['observed_on'].between(left, right))
        ].copy()

        if filt.empty:
            display(HTML("<b>No observations for current filters.</b>"))
            return

        # center
        center = _bounds_latlon(filt)

        m = folium.Map(location=center, zoom_start=2, tiles=w_tiles.value)

        # layers per species
        if w_heatmap.value:
            for sp, sub in filt.groupby('species'):
                layer = folium.FeatureGroup(name=f"Heat — {sp}", show=True)
                points = sub[['lat','lon']].values.tolist()
                plugins.HeatMap(points, radius=12, blur=18, min_opacity=0.35).add_to(layer)
                layer.add_to(m)

        if w_points.value:
            # color palette (repeat if needed)
            palette = ['blue','red','green','purple','orange','darkred','lightred','beige','darkblue',
                       'darkgreen','cadetblue','darkpurple','white','pink','lightblue','lightgreen','gray',
                       'black','lightgray']
            colors = {sp:c for sp, c in zip(filt['species'].unique(), palette * 10)}

            for sp, sub in filt.groupby('species'):
                layer_p = folium.FeatureGroup(name=f"Pts — {sp}", show=(not w_heatmap.value))
                for _, r in sub.iterrows():
                    popup = folium.Popup(
                        f"<b>{r.get('common_name') or ''}</b><br>"
                        f"<i>{r['species']}</i><br>"
                        f"{r['observed_on'].strftime('%Y-%m-%d')}<br>"
                        f"{(r.get('place_guess') or '')}<br>"
                        f"@{r.get('user') or ''}",
                        max_width=240
                    )
                    folium.CircleMarker(
                        [r['lat'], r['lon']],
                        radius=w_point_size.value,
                        color=colors.get(sp,'gray'),
                        fill=True, fill_opacity=0.7,
                        weight=0.5,
                        popup=popup
                    ).add_to(layer_p)
                layer_p.add_to(m)

        folium.LayerControl(collapsed=False).add_to(m)

        display(m)
        w_status.value = f"<span style='color:#4caf50'>Rendered {len(filt):,} observations • {len(sel_species)} species</span>"

def export_html(_):
    # rebuild map using current filters and save
    left, right = w_dates.value
    left = pd.to_datetime(left).tz_localize('UTC')
    right = pd.to_datetime(right).tz_localize('UTC') + pd.Timedelta(days=1) - pd.Timedelta(milliseconds=1)
    sel_species = list(w_species.value) if w_species.value else sp_opts

    filt = work[
        work['species'].isin(sel_species) &
        (work['observed_on'].between(left, right))
    ].copy()
    if filt.empty:
        w_status.value = "<span style='color:#f44336'>Nothing to export for current filters.</span>"
        return

    center = _bounds_latlon(filt)
    m = folium.Map(location=center, zoom_start=2, tiles=w_tiles.value)

    if w_heatmap.value:
        for sp, sub in filt.groupby('species'):
            layer = folium.FeatureGroup(name=f"Heat — {sp}", show=True)
            plugins.HeatMap(sub[['lat','lon']].values.tolist(),
                            radius=12, blur=18, min_opacity=0.35).add_to(layer)
            layer.add_to(m)

    if w_points.value:
        palette = ['blue','red','green','purple','orange','darkred','lightred','beige','darkblue',
                   'darkgreen','cadetblue','darkpurple','white','pink','lightblue','lightgreen','gray',
                   'black','lightgray']
        colors = {sp:c for sp, c in zip(filt['species'].unique(), palette * 10)}
        for sp, sub in filt.groupby('species'):
            layer_p = folium.FeatureGroup(name=f"Pts — {sp}", show=(not w_heatmap.value))
            for _, r in sub.iterrows():
                popup = folium.Popup(
                    f"<b>{r.get('common_name') or ''}</b><br>"
                    f"<i>{r['species']}</i><br>"
                    f"{r['observed_on'].strftime('%Y-%m-%d')}<br>"
                    f"{(r.get('place_guess') or '')}<br>"
                    f"@{r.get('user') or ''}",
                    max_width=240
                )
                folium.CircleMarker(
                    [r['lat'], r['lon']],
                    radius=w_point_size.value,
                    color=colors.get(sp,'gray'),
                    fill=True, fill_opacity=0.7,
                    weight=0.5,
                    popup=popup
                ).add_to(layer_p)
            layer_p.add_to(m)

    folium.LayerControl(collapsed=False).add_to(m)

    fname = "inat_dashboard_map.html"
    m.save(fname)
    w_status.value = f"<span style='color:#4caf50'>Exported: <code>{fname}</code></span>"

# hook up events
for w in (w_species, w_heatmap, w_points, w_point_size, w_tiles, w_dates):
    w.observe(lambda _ : render_map(), names='value')
w_export.on_click(export_html)

# initial render
render_map()

# layout
controls_col = VBox([
    HTML("<b>Filters</b>"),
    w_species,
    w_tiles,
    HBox([w_heatmap, w_points]),
    w_point_size,
    HTML("<b>Date range</b>"),
    w_dates,
    HBox([w_export, w_status]),
], layout=Layout(width='640px'))

ui = HBox([controls_col], layout=Layout(align_items='flex-start'))
display(ui, out_map)

